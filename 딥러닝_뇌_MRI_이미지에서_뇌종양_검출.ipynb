{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 13898343,
          "sourceType": "datasetVersion",
          "datasetId": 8854728
        }
      ],
      "dockerImageVersionId": 31192,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekdls02/ekdls2025/blob/main/%EB%94%A5%EB%9F%AC%EB%8B%9D_%EA%B3%BC%EC%A0%9C4_%EB%87%8C_MRI_%EC%9D%B4%EB%AF%B8%EC%A7%80%EC%97%90%EC%84%9C_%EB%87%8C%EC%A2%85%EC%96%91_%EA%B2%80%EC%B6%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 라이브러리 임포트 및 설정 (EfficientNetB0 클래스 명시적으로 임포트)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input\n",
        "# EfficientNetB0 클래스를 직접 임포트하여 set_efficientnet_trainable 함수의 TypeError 해결\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import os\n",
        "\n",
        "# ImageNet 통계값 (수동 정규화에 사용)\n",
        "IMAGENET_MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
        "IMAGENET_STDDEV = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
        "\n",
        "# 2. 경로 및 Seed 설정\n",
        "TRAIN_PATH = \"/content/train.npz\"\n",
        "TEST_PATH = \"/content/test.npz\"\n",
        "SAMPLE_PATH = \"/content/submission.csv\"\n",
        "\n",
        "MODEL_OUTPUT_PATH = \"/content/new_submission/\"\n",
        "os.makedirs(MODEL_OUTPUT_PATH, exist_ok=True)\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# 3. 데이터 로드 및 전처리 (수정: 레이블 매핑 및 수동 ImageNet 정규화)\n",
        "train_data = np.load(TRAIN_PATH)\n",
        "x_train_raw = train_data['x']\n",
        "y_train_raw = train_data['y']\n",
        "\n",
        "# 1채널 흑백 이미지를 3채널로 복사\n",
        "x_train_temp = np.repeat(x_train_raw[..., np.newaxis], 3, axis=-1).astype('float32')\n",
        "\n",
        "# 수동 ImageNet 표준 정규화 적용 (x / 255 - mean) / std\n",
        "x_train = (x_train_temp / 255.0 - IMAGENET_MEAN) / IMAGENET_STDDEV\n",
        "\n",
        "# 수정: 문자열 레이블을 이진 숫자로 변환 (ValueError 해결)\n",
        "# y_train_raw의 내용이 ['normal', 'tumor', ...] 형태라고 가정\n",
        "label_map = {'normal': 0, 'tumor': 1}\n",
        "y_encoded = np.array([label_map[i] for i in y_train_raw])\n",
        "\n",
        "# Input Shape 정의\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "\n",
        "# 4. Data Generator (수정: 증강 강도 약화)\n",
        "BATCH_SIZE = 8 # Batch Size 축소\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=5,           # 5도로 축소\n",
        "    width_shift_range=0.1,      # 0.1로 축소\n",
        "    height_shift_range=0.1,     # 0.1로 축소\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False,\n",
        "    zoom_range=0.1,             # 0.1로 축소\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "def get_generator(x, y):\n",
        "    return datagen.flow(x, y, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "\n",
        "# 5. 모델 정의 (수정: set_efficientnet_trainable 안정화, Head 간소화/규제 강화)\n",
        "\n",
        "def set_efficientnet_trainable(model, trainable_percent):\n",
        "    \"\"\"\n",
        "    EfficientNetB0 내부 레이어만 찾아 trainable_percent 비율만큼 상위 레이어를 학습 가능하게 설정합니다.\n",
        "    \"\"\"\n",
        "    efficientnet_base_model = None\n",
        "\n",
        "    # 수정: 레이어 타입 대신, 이름에 'efficientnetb0'이 포함된 레이어를 찾습니다.\n",
        "    # 이렇게 하면 isinstance() 관련 TypeError를 회피할 수 있습니다.\n",
        "    for layer in model.layers:\n",
        "        if 'efficientnetb0' in layer.name.lower():\n",
        "            efficientnet_base_model = layer\n",
        "            break\n",
        "\n",
        "    if efficientnet_base_model is None:\n",
        "        print(\"경고: EfficientNetB0 Base Model 레이어를 찾을 수 없습니다.\")\n",
        "        return\n",
        "\n",
        "    # Base Model 내부의 학습 가능한 레이어만 필터링합니다.\n",
        "    efficientnet_layers = [\n",
        "        l for l in efficientnet_base_model.layers\n",
        "        if 'block' in l.name or 'stem' in l.name or 'top' in l.name\n",
        "    ]\n",
        "\n",
        "    num_layers = len(efficientnet_layers)\n",
        "    if num_layers == 0:\n",
        "        print(\"경고: EfficientNetB0의 주요 블록 레이어를 찾을 수 없습니다.\")\n",
        "        return\n",
        "\n",
        "    # 학습 가능한 레이어의 시작 인덱스 (상위 trainable_percent만 학습)\n",
        "    trainable_start_index = int(num_layers * (1 - trainable_percent))\n",
        "\n",
        "    layers_to_freeze = 0\n",
        "    layers_to_train = 0\n",
        "\n",
        "    for i, layer in enumerate(efficientnet_layers):\n",
        "        if i < trainable_start_index:\n",
        "            layer.trainable = False\n",
        "            layers_to_freeze += 1\n",
        "        else:\n",
        "            layer.trainable = True\n",
        "            layers_to_train += 1\n",
        "\n",
        "    print(f\"EfficientNetB0 내부: {layers_to_freeze}개 레이어 동결, {layers_to_train}개 레이어 학습 가능.\")\n",
        "\n",
        "def build_model(input_shape, base_model_trainable=False, trainable_percent=0.05):\n",
        "    clear_session()\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # EfficientNetB0 로드\n",
        "    base_model = EfficientNetB0(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_tensor=inputs\n",
        "        # 'trainable=False' 인수를 제거\n",
        "    )\n",
        "\n",
        "    # 수정: 모델 생성 직후, 명시적으로 동결\n",
        "    # Head 학습 시에는 base_model.trainable=False가 되어야 합니다.\n",
        "    # Fine-Tuning 시에는 아래 if 블록에서 다시 True가 됩니다.\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # 3. Model Head 구성\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Head 간소화 및 L2 규제 강화\n",
        "    x = Dense(256, activation='relu', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    outputs = Dense(1, activation='sigmoid', dtype='float32')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    if base_model_trainable:\n",
        "        # Fine-Tuning 시\n",
        "        base_model.trainable = True # Base Model 전체를 학습 가능하도록 설정\n",
        "\n",
        "        # Base Model 내부 레이어에 직접 접근하여 동결 및 학습 설정\n",
        "        efficientnet_layers = [\n",
        "            l for l in base_model.layers\n",
        "            if 'block' in l.name or 'stem' in l.name or 'top' in l.name\n",
        "        ]\n",
        "        num_layers = len(efficientnet_layers)\n",
        "        trainable_start_index = int(num_layers * (1 - trainable_percent))\n",
        "\n",
        "        for i, layer in enumerate(efficientnet_layers):\n",
        "            if i < trainable_start_index:\n",
        "                layer.trainable = False\n",
        "            else:\n",
        "                layer.trainable = True\n",
        "\n",
        "        # 출력 메시지\n",
        "        print(f\"EfficientNetB0 내부: {trainable_start_index}개 레이어 동결, {num_layers - trainable_start_index}개 레이어 학습 가능.\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# 6. Stratified K-Fold 학습 + Fine-Tuning (수정: EarlyStopping/LR 조정)\n",
        "N_SPLITS = 5\n",
        "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
        "ensemble_models = []\n",
        "fold_val_accuracies = []\n",
        "\n",
        "# 수정: 콜백 설정 (patience 축소)\n",
        "early_stop_head = EarlyStopping(monitor='val_accuracy', mode='max', patience=5, restore_best_weights=True) # 8 -> 5\n",
        "early_stop_ft = EarlyStopping(monitor='val_accuracy', mode='max', patience=8, restore_best_weights=True)  # 15 -> 8\n",
        "reduce_lr_ft = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3, min_lr=1e-7) # 5 -> 3\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(x_train, y_encoded)):\n",
        "    print(f\"Fold {fold+1}/{N_SPLITS}\")\n",
        "    X_tr, X_val = x_train[train_idx], x_train[val_idx]\n",
        "    y_tr, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
        "\n",
        "    ft_weights_path = os.path.join(MODEL_OUTPUT_PATH, f\"fold{fold+1}_best_ft.keras\")\n",
        "    checkpoint_cb = ModelCheckpoint(ft_weights_path, monitor='val_accuracy',\n",
        "                                    mode='max', save_best_only=True, verbose=1)\n",
        "\n",
        "    # 1) Head 학습 (Base Model 동결)\n",
        "    print(\"1. Head (분류기) 학습 시작\")\n",
        "    model_head = build_model(input_shape, base_model_trainable=False)\n",
        "\n",
        "    model_head.compile(optimizer=SGD(learning_rate=1e-2, momentum=0.9),\n",
        "                       loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model_head.fit(get_generator(X_tr, y_tr), validation_data=(X_val, y_val),\n",
        "                   epochs=50, callbacks=[early_stop_head], verbose=1)\n",
        "\n",
        "    # 2) Fine-Tuning (수정: Base Model 상위 5% 학습 및 LR 하향)\n",
        "    print(\"2. Fine-Tuning 시작\")\n",
        "\n",
        "    # 수정: Base Model의 상위 5%만 Fine-Tuning\n",
        "    model_ft = build_model(input_shape, base_model_trainable=True, trainable_percent=0.05)\n",
        "    model_ft.set_weights(model_head.get_weights())\n",
        "\n",
        "    # 수정: Adam Learning Rate를 5e-6으로 하향\n",
        "    model_ft.compile(optimizer=Adam(learning_rate=5e-6),\n",
        "                      loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model_ft.fit(get_generator(X_tr, y_tr), validation_data=(X_val, y_val),\n",
        "                   epochs=150,\n",
        "                   callbacks=[early_stop_ft, reduce_lr_ft, checkpoint_cb], verbose=1)\n",
        "\n",
        "    # 3) 최종 평가: 최적의 Fine-Tuning 모델 로드 후 평가\n",
        "    model_final = tf.keras.models.load_model(ft_weights_path)\n",
        "\n",
        "    val_loss, val_acc = model_final.evaluate(X_val, y_val, verbose=0)\n",
        "    fold_val_accuracies.append(val_acc)\n",
        "    print(f\"Fold {fold+1} 최종 검증 정확도: {val_acc:.5f}\")\n",
        "\n",
        "    ensemble_models.append(ft_weights_path)\n",
        "    clear_session()\n",
        "\n",
        "\n",
        "# 7. K-Fold 평균 검증 정확도\n",
        "mean_acc = np.mean(fold_val_accuracies)\n",
        "print(f\"K-Fold 평균 검증 정확도 ({N_SPLITS} Folds): {mean_acc:.5f}\")\n",
        "\n",
        "\n",
        "# 8. Test 예측 및 Submission (앙상블 로직)\n",
        "# Test 데이터 로드\n",
        "test_data = np.load(TEST_PATH)\n",
        "x_test_raw = test_data['x']\n",
        "\n",
        "# Test 데이터도 학습 데이터와 동일하게 수동 ImageNet 정규화 적용\n",
        "x_test_temp = np.repeat(x_test_raw[..., np.newaxis], 3, axis=-1).astype('float32')\n",
        "x_test = (x_test_temp / 255.0 - IMAGENET_MEAN) / IMAGENET_STDDEV\n",
        "\n",
        "test_preds_prob = []\n",
        "# 각 Fold의 최적 모델로 예측 수행\n",
        "for model_path in ensemble_models:\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "    preds_prob = model.predict(x_test, verbose=0)\n",
        "    test_preds_prob.append(preds_prob)\n",
        "    clear_session()\n",
        "\n",
        "# 평균 예측 확률 계산 및 이진 분류\n",
        "y_test_mean = np.mean(test_preds_prob, axis=0)\n",
        "y_test_pred = (y_test_mean[:,0] >= 0.5).astype(int)\n",
        "\n",
        "# 레이블 역변환\n",
        "label_map_reverse = {0:'normal', 1:'tumor'}\n",
        "y_test_str = np.array([label_map_reverse[i] for i in y_test_pred])\n",
        "\n",
        "# Submission 파일 생성\n",
        "sample = pd.read_csv(SAMPLE_PATH)\n",
        "sample[\"result\"] = y_test_str\n",
        "submission_file_name = \"submission_final_optimized.csv\"\n",
        "sample.to_csv(submission_file_name, index=False)\n",
        "print(f\"제출 파일 생성 완료: {submission_file_name}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-30T11:43:13.121598Z",
          "iopub.execute_input": "2025-11-30T11:43:13.121814Z",
          "iopub.status.idle": "2025-11-30T11:54:27.947385Z",
          "shell.execute_reply.started": "2025-11-30T11:43:13.121797Z",
          "shell.execute_reply": "2025-11-30T11:54:27.946483Z"
        },
        "id": "JrMgON0yqe4x",
        "outputId": "9eab0f19-4bf8-4e37-be4f-e4560e082cda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1/5\n",
            "1. Head (분류기) 학습 시작\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 2s/step - accuracy: 0.5529 - loss: 1.1239 - val_accuracy: 0.4878 - val_loss: 1.1120\n",
            "Epoch 2/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.4827 - loss: 1.1459 - val_accuracy: 0.7317 - val_loss: 1.0060\n",
            "Epoch 3/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.6292 - loss: 1.0610 - val_accuracy: 0.6098 - val_loss: 1.0431\n",
            "Epoch 4/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.6371 - loss: 1.1481 - val_accuracy: 0.6585 - val_loss: 1.0170\n",
            "Epoch 5/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.6445 - loss: 1.0325 - val_accuracy: 0.7073 - val_loss: 0.9853\n",
            "Epoch 6/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.6614 - loss: 1.0161 - val_accuracy: 0.8049 - val_loss: 0.9651\n",
            "Epoch 7/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - accuracy: 0.6720 - loss: 1.0847 - val_accuracy: 0.6098 - val_loss: 1.0590\n",
            "Epoch 8/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.6453 - loss: 1.0753 - val_accuracy: 0.7073 - val_loss: 0.9944\n",
            "Epoch 9/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.7093 - loss: 0.9958 - val_accuracy: 0.7073 - val_loss: 1.0128\n",
            "Epoch 10/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.6814 - loss: 1.0310 - val_accuracy: 0.6341 - val_loss: 0.9956\n",
            "Epoch 11/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.5727 - loss: 1.0243 - val_accuracy: 0.6341 - val_loss: 0.9811\n",
            "2. Fine-Tuning 시작\n",
            "EfficientNetB0 내부: 222개 레이어 동결, 12개 레이어 학습 가능.\n",
            "Epoch 1/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575ms/step - accuracy: 0.5804 - loss: 1.0648\n",
            "Epoch 1: val_accuracy improved from -inf to 0.70732, saving model to /content/new_submission/fold1_best_ft.keras\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 1s/step - accuracy: 0.5817 - loss: 1.0646 - val_accuracy: 0.7073 - val_loss: 1.0025 - learning_rate: 5.0000e-06\n",
            "Epoch 2/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5395 - loss: 1.0802\n",
            "Epoch 2: val_accuracy did not improve from 0.70732\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.5395 - loss: 1.0805 - val_accuracy: 0.7073 - val_loss: 1.0370 - learning_rate: 5.0000e-06\n",
            "Epoch 3/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5581 - loss: 1.0687\n",
            "Epoch 3: val_accuracy did not improve from 0.70732\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.5578 - loss: 1.0687 - val_accuracy: 0.6341 - val_loss: 1.0595 - learning_rate: 5.0000e-06\n",
            "Epoch 4/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6036 - loss: 1.0568\n",
            "Epoch 4: val_accuracy did not improve from 0.70732\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - accuracy: 0.6049 - loss: 1.0567 - val_accuracy: 0.6341 - val_loss: 1.0745 - learning_rate: 5.0000e-06\n",
            "Epoch 5/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6504 - loss: 1.0532\n",
            "Epoch 5: val_accuracy did not improve from 0.70732\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.6497 - loss: 1.0530 - val_accuracy: 0.6585 - val_loss: 1.0796 - learning_rate: 1.5000e-06\n",
            "Epoch 6/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6006 - loss: 1.0638\n",
            "Epoch 6: val_accuracy did not improve from 0.70732\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.6004 - loss: 1.0640 - val_accuracy: 0.6585 - val_loss: 1.0816 - learning_rate: 1.5000e-06\n",
            "Epoch 7/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6655 - loss: 1.0474\n",
            "Epoch 7: val_accuracy did not improve from 0.70732\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.6666 - loss: 1.0475 - val_accuracy: 0.6829 - val_loss: 1.0790 - learning_rate: 1.5000e-06\n",
            "Epoch 8/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6610 - loss: 1.0514\n",
            "Epoch 8: val_accuracy did not improve from 0.70732\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.6597 - loss: 1.0513 - val_accuracy: 0.6829 - val_loss: 1.0746 - learning_rate: 4.5000e-07\n",
            "Epoch 9/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6226 - loss: 1.0560\n",
            "Epoch 9: val_accuracy did not improve from 0.70732\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.6231 - loss: 1.0552 - val_accuracy: 0.6829 - val_loss: 1.0706 - learning_rate: 4.5000e-07\n",
            "Fold 1 최종 검증 정확도: 0.70732\n",
            "Fold 2/5\n",
            "1. Head (분류기) 학습 시작\n",
            "Epoch 1/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 0.5050 - loss: 1.1555 - val_accuracy: 0.6098 - val_loss: 1.1591\n",
            "Epoch 2/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.6709 - loss: 1.0065 - val_accuracy: 0.6585 - val_loss: 1.0280\n",
            "Epoch 3/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.5693 - loss: 1.1030 - val_accuracy: 0.6098 - val_loss: 1.1514\n",
            "Epoch 4/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.7436 - loss: 1.0341 - val_accuracy: 0.5854 - val_loss: 1.0132\n",
            "Epoch 5/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - accuracy: 0.6773 - loss: 1.0394 - val_accuracy: 0.6098 - val_loss: 1.0677\n",
            "Epoch 6/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.6728 - loss: 1.0259 - val_accuracy: 0.6341 - val_loss: 1.0138\n",
            "Epoch 7/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.6683 - loss: 1.0423 - val_accuracy: 0.5122 - val_loss: 1.1366\n",
            "2. Fine-Tuning 시작\n",
            "EfficientNetB0 내부: 222개 레이어 동결, 12개 레이어 학습 가능.\n",
            "Epoch 1/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552ms/step - accuracy: 0.5819 - loss: 1.0822\n",
            "Epoch 1: val_accuracy improved from -inf to 0.70732, saving model to /content/new_submission/fold2_best_ft.keras\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 1s/step - accuracy: 0.5811 - loss: 1.0826 - val_accuracy: 0.7073 - val_loss: 1.0344 - learning_rate: 5.0000e-06\n",
            "Epoch 2/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6182 - loss: 1.0688\n",
            "Epoch 2: val_accuracy did not improve from 0.70732\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.6197 - loss: 1.0684 - val_accuracy: 0.6829 - val_loss: 1.0427 - learning_rate: 5.0000e-06\n",
            "Epoch 3/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5612 - loss: 1.0985\n",
            "Epoch 3: val_accuracy did not improve from 0.70732\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.5628 - loss: 1.0972 - val_accuracy: 0.6585 - val_loss: 1.0509 - learning_rate: 5.0000e-06\n",
            "Epoch 4/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6570 - loss: 1.0556\n",
            "Epoch 4: val_accuracy did not improve from 0.70732\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.6562 - loss: 1.0554 - val_accuracy: 0.6585 - val_loss: 1.0544 - learning_rate: 5.0000e-06\n",
            "Epoch 5/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6077 - loss: 1.0571\n",
            "Epoch 5: val_accuracy did not improve from 0.70732\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.6080 - loss: 1.0577 - val_accuracy: 0.6341 - val_loss: 1.0565 - learning_rate: 1.5000e-06\n",
            "Epoch 6/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5718 - loss: 1.0977\n",
            "Epoch 6: val_accuracy did not improve from 0.70732\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.5740 - loss: 1.0962 - val_accuracy: 0.6341 - val_loss: 1.0602 - learning_rate: 1.5000e-06\n",
            "Epoch 7/150\n",
            "\u001b[1m20/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.6319 - loss: 1.0543\n",
            "Epoch 7: val_accuracy did not improve from 0.70732\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.6287 - loss: 1.0575 - val_accuracy: 0.6341 - val_loss: 1.0601 - learning_rate: 1.5000e-06\n",
            "Epoch 8/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6580 - loss: 1.0513\n",
            "Epoch 8: val_accuracy did not improve from 0.70732\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.6566 - loss: 1.0516 - val_accuracy: 0.6098 - val_loss: 1.0616 - learning_rate: 4.5000e-07\n",
            "Epoch 9/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5443 - loss: 1.0891\n",
            "Epoch 9: val_accuracy did not improve from 0.70732\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.5495 - loss: 1.0867 - val_accuracy: 0.6098 - val_loss: 1.0601 - learning_rate: 4.5000e-07\n",
            "Fold 2 최종 검증 정확도: 0.70732\n",
            "Fold 3/5\n",
            "1. Head (분류기) 학습 시작\n",
            "Epoch 1/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 1s/step - accuracy: 0.6130 - loss: 1.1145 - val_accuracy: 0.7000 - val_loss: 1.0043\n",
            "Epoch 2/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.6489 - loss: 1.0638 - val_accuracy: 0.7000 - val_loss: 1.0204\n",
            "Epoch 3/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.6027 - loss: 1.1228 - val_accuracy: 0.6750 - val_loss: 0.9905\n",
            "Epoch 4/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - accuracy: 0.5931 - loss: 1.1095 - val_accuracy: 0.5750 - val_loss: 1.0783\n",
            "Epoch 5/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.6436 - loss: 1.0832 - val_accuracy: 0.6250 - val_loss: 1.0001\n",
            "Epoch 6/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.6792 - loss: 1.0136 - val_accuracy: 0.7500 - val_loss: 1.0007\n",
            "Epoch 7/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.7063 - loss: 1.0088 - val_accuracy: 0.6750 - val_loss: 1.0009\n",
            "Epoch 8/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.7264 - loss: 0.9546 - val_accuracy: 0.6750 - val_loss: 0.9861\n",
            "Epoch 9/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.7072 - loss: 0.9370 - val_accuracy: 0.6000 - val_loss: 1.0554\n",
            "Epoch 10/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.6760 - loss: 1.0829 - val_accuracy: 0.7250 - val_loss: 0.9609\n",
            "Epoch 11/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 0.6131 - loss: 1.0043 - val_accuracy: 0.6750 - val_loss: 0.9775\n",
            "2. Fine-Tuning 시작\n",
            "EfficientNetB0 내부: 222개 레이어 동결, 12개 레이어 학습 가능.\n",
            "Epoch 1/150\n",
            "\u001b[1m19/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 650ms/step - accuracy: 0.6547 - loss: 1.0526\n",
            "Epoch 1: val_accuracy improved from -inf to 0.67500, saving model to /content/new_submission/fold3_best_ft.keras\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 1s/step - accuracy: 0.6513 - loss: 1.0529 - val_accuracy: 0.6750 - val_loss: 1.0425 - learning_rate: 5.0000e-06\n",
            "Epoch 2/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6204 - loss: 1.0265\n",
            "Epoch 2: val_accuracy did not improve from 0.67500\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.6211 - loss: 1.0265 - val_accuracy: 0.6000 - val_loss: 1.0602 - learning_rate: 5.0000e-06\n",
            "Epoch 3/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6692 - loss: 0.9959\n",
            "Epoch 3: val_accuracy did not improve from 0.67500\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.6705 - loss: 0.9963 - val_accuracy: 0.6000 - val_loss: 1.0673 - learning_rate: 5.0000e-06\n",
            "Epoch 4/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6339 - loss: 1.0405\n",
            "Epoch 4: val_accuracy did not improve from 0.67500\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.6351 - loss: 1.0399 - val_accuracy: 0.6250 - val_loss: 1.0616 - learning_rate: 5.0000e-06\n",
            "Epoch 5/150\n",
            "\u001b[1m20/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6869 - loss: 1.0180\n",
            "Epoch 5: val_accuracy did not improve from 0.67500\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.6873 - loss: 1.0197 - val_accuracy: 0.6500 - val_loss: 1.0575 - learning_rate: 1.5000e-06\n",
            "Epoch 6/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6223 - loss: 1.0117\n",
            "Epoch 6: val_accuracy did not improve from 0.67500\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.6237 - loss: 1.0117 - val_accuracy: 0.6500 - val_loss: 1.0484 - learning_rate: 1.5000e-06\n",
            "Epoch 7/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6772 - loss: 1.0160\n",
            "Epoch 7: val_accuracy did not improve from 0.67500\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.6770 - loss: 1.0159 - val_accuracy: 0.6750 - val_loss: 1.0419 - learning_rate: 1.5000e-06\n",
            "Epoch 8/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.7075 - loss: 0.9860\n",
            "Epoch 8: val_accuracy improved from 0.67500 to 0.70000, saving model to /content/new_submission/fold3_best_ft.keras\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 153ms/step - accuracy: 0.7046 - loss: 0.9883 - val_accuracy: 0.7000 - val_loss: 1.0353 - learning_rate: 1.5000e-06\n",
            "Epoch 9/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7849 - loss: 0.9438\n",
            "Epoch 9: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.7846 - loss: 0.9444 - val_accuracy: 0.7000 - val_loss: 1.0282 - learning_rate: 1.5000e-06\n",
            "Epoch 10/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6349 - loss: 1.0504\n",
            "Epoch 10: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.6361 - loss: 1.0500 - val_accuracy: 0.6750 - val_loss: 1.0216 - learning_rate: 1.5000e-06\n",
            "Epoch 11/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6643 - loss: 0.9989\n",
            "Epoch 11: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.6638 - loss: 0.9993 - val_accuracy: 0.6750 - val_loss: 1.0164 - learning_rate: 1.5000e-06\n",
            "Epoch 12/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6511 - loss: 1.0791\n",
            "Epoch 12: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.6532 - loss: 1.0773 - val_accuracy: 0.6750 - val_loss: 1.0139 - learning_rate: 1.5000e-06\n",
            "Epoch 13/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.6709 - loss: 1.0336\n",
            "Epoch 13: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.6716 - loss: 1.0330 - val_accuracy: 0.6750 - val_loss: 1.0096 - learning_rate: 1.5000e-06\n",
            "Epoch 14/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6517 - loss: 0.9961\n",
            "Epoch 14: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.6524 - loss: 0.9970 - val_accuracy: 0.6750 - val_loss: 1.0064 - learning_rate: 1.5000e-06\n",
            "Epoch 15/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.7175 - loss: 1.0242\n",
            "Epoch 15: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.7169 - loss: 1.0242 - val_accuracy: 0.6750 - val_loss: 1.0034 - learning_rate: 1.5000e-06\n",
            "Epoch 16/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7027 - loss: 1.0138\n",
            "Epoch 16: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.7008 - loss: 1.0142 - val_accuracy: 0.7000 - val_loss: 1.0013 - learning_rate: 1.5000e-06\n",
            "Fold 3 최종 검증 정확도: 0.70000\n",
            "Fold 4/5\n",
            "1. Head (분류기) 학습 시작\n",
            "Epoch 1/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.5981 - loss: 1.1475 - val_accuracy: 0.6000 - val_loss: 1.0993\n",
            "Epoch 2/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.6294 - loss: 1.1525 - val_accuracy: 0.6750 - val_loss: 1.0897\n",
            "Epoch 3/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.6229 - loss: 1.0960 - val_accuracy: 0.6000 - val_loss: 1.0516\n",
            "Epoch 4/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.5984 - loss: 1.0666 - val_accuracy: 0.6250 - val_loss: 1.0423\n",
            "Epoch 5/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.6518 - loss: 1.0207 - val_accuracy: 0.6750 - val_loss: 1.0234\n",
            "Epoch 6/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.6530 - loss: 1.0370 - val_accuracy: 0.7000 - val_loss: 1.0221\n",
            "Epoch 7/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 0.6376 - loss: 0.9814 - val_accuracy: 0.6500 - val_loss: 1.0534\n",
            "Epoch 8/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.7115 - loss: 1.0454 - val_accuracy: 0.7250 - val_loss: 1.0153\n",
            "Epoch 9/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.7404 - loss: 0.9612 - val_accuracy: 0.6750 - val_loss: 1.0050\n",
            "Epoch 10/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.7618 - loss: 0.9653 - val_accuracy: 0.6750 - val_loss: 1.0036\n",
            "Epoch 11/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.6315 - loss: 1.0276 - val_accuracy: 0.6750 - val_loss: 0.9891\n",
            "Epoch 12/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.7243 - loss: 0.9888 - val_accuracy: 0.7500 - val_loss: 0.9934\n",
            "Epoch 13/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.7079 - loss: 0.9865 - val_accuracy: 0.6750 - val_loss: 1.0016\n",
            "Epoch 14/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.7343 - loss: 0.9750 - val_accuracy: 0.6250 - val_loss: 0.9833\n",
            "Epoch 15/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.5968 - loss: 1.0337 - val_accuracy: 0.6750 - val_loss: 1.0071\n",
            "Epoch 16/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.7049 - loss: 0.9833 - val_accuracy: 0.7000 - val_loss: 1.0091\n",
            "Epoch 17/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.5974 - loss: 1.1205 - val_accuracy: 0.6250 - val_loss: 1.0226\n",
            "2. Fine-Tuning 시작\n",
            "EfficientNetB0 내부: 222개 레이어 동결, 12개 레이어 학습 가능.\n",
            "Epoch 1/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575ms/step - accuracy: 0.6918 - loss: 1.0083\n",
            "Epoch 1: val_accuracy improved from -inf to 0.72500, saving model to /content/new_submission/fold4_best_ft.keras\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 1s/step - accuracy: 0.6924 - loss: 1.0084 - val_accuracy: 0.7250 - val_loss: 0.9801 - learning_rate: 5.0000e-06\n",
            "Epoch 2/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.7144 - loss: 0.9753\n",
            "Epoch 2: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.7125 - loss: 0.9773 - val_accuracy: 0.6750 - val_loss: 0.9850 - learning_rate: 5.0000e-06\n",
            "Epoch 3/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6050 - loss: 1.0380\n",
            "Epoch 3: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.6072 - loss: 1.0367 - val_accuracy: 0.6750 - val_loss: 0.9911 - learning_rate: 5.0000e-06\n",
            "Epoch 4/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6320 - loss: 1.0278\n",
            "Epoch 4: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.6327 - loss: 1.0270 - val_accuracy: 0.7000 - val_loss: 0.9960 - learning_rate: 5.0000e-06\n",
            "Epoch 5/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.6447 - loss: 1.0669\n",
            "Epoch 5: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.6457 - loss: 1.0642 - val_accuracy: 0.7000 - val_loss: 1.0000 - learning_rate: 1.5000e-06\n",
            "Epoch 6/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6058 - loss: 1.0564\n",
            "Epoch 6: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.6085 - loss: 1.0544 - val_accuracy: 0.6750 - val_loss: 1.0017 - learning_rate: 1.5000e-06\n",
            "Epoch 7/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6530 - loss: 1.0158\n",
            "Epoch 7: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.6528 - loss: 1.0151 - val_accuracy: 0.6750 - val_loss: 1.0021 - learning_rate: 1.5000e-06\n",
            "Epoch 8/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.6517 - loss: 0.9919\n",
            "Epoch 8: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.6516 - loss: 0.9920 - val_accuracy: 0.6750 - val_loss: 1.0019 - learning_rate: 4.5000e-07\n",
            "Epoch 9/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6562 - loss: 0.9996\n",
            "Epoch 9: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.6555 - loss: 0.9996 - val_accuracy: 0.6750 - val_loss: 1.0012 - learning_rate: 4.5000e-07\n",
            "Fold 4 최종 검증 정확도: 0.72500\n",
            "Fold 5/5\n",
            "1. Head (분류기) 학습 시작\n",
            "Epoch 1/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.5695 - loss: 1.1287 - val_accuracy: 0.5500 - val_loss: 1.0757\n",
            "Epoch 2/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.5242 - loss: 1.1756 - val_accuracy: 0.6250 - val_loss: 1.0626\n",
            "Epoch 3/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.6312 - loss: 1.0792 - val_accuracy: 0.7000 - val_loss: 1.0525\n",
            "Epoch 4/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.6730 - loss: 1.0423 - val_accuracy: 0.6500 - val_loss: 1.0566\n",
            "Epoch 5/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.6083 - loss: 1.0959 - val_accuracy: 0.6500 - val_loss: 1.0341\n",
            "Epoch 6/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.6456 - loss: 1.0214 - val_accuracy: 0.6250 - val_loss: 1.0197\n",
            "Epoch 7/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.6872 - loss: 1.0114 - val_accuracy: 0.7250 - val_loss: 0.9924\n",
            "Epoch 8/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.5840 - loss: 1.0692 - val_accuracy: 0.7000 - val_loss: 0.9903\n",
            "Epoch 9/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.6811 - loss: 1.0233 - val_accuracy: 0.5750 - val_loss: 1.0652\n",
            "Epoch 10/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.6946 - loss: 1.0125 - val_accuracy: 0.6500 - val_loss: 1.0030\n",
            "Epoch 11/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.6007 - loss: 1.0474 - val_accuracy: 0.6750 - val_loss: 0.9869\n",
            "Epoch 12/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - accuracy: 0.7261 - loss: 0.9829 - val_accuracy: 0.7500 - val_loss: 0.9500\n",
            "Epoch 13/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.5903 - loss: 1.0897 - val_accuracy: 0.7250 - val_loss: 0.9561\n",
            "Epoch 14/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.6310 - loss: 1.0067 - val_accuracy: 0.7000 - val_loss: 0.9566\n",
            "Epoch 15/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.6592 - loss: 0.9814 - val_accuracy: 0.8000 - val_loss: 0.9705\n",
            "Epoch 16/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.7563 - loss: 0.9241 - val_accuracy: 0.7500 - val_loss: 0.9545\n",
            "Epoch 17/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.6951 - loss: 0.9336 - val_accuracy: 0.7500 - val_loss: 0.9653\n",
            "Epoch 18/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.6190 - loss: 0.9732 - val_accuracy: 0.7250 - val_loss: 0.9667\n",
            "Epoch 19/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.6455 - loss: 1.0322 - val_accuracy: 0.7500 - val_loss: 0.9392\n",
            "Epoch 20/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - accuracy: 0.6371 - loss: 0.9216 - val_accuracy: 0.7250 - val_loss: 0.9437\n",
            "2. Fine-Tuning 시작\n",
            "EfficientNetB0 내부: 222개 레이어 동결, 12개 레이어 학습 가능.\n",
            "Epoch 1/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619ms/step - accuracy: 0.6853 - loss: 0.9464\n",
            "Epoch 1: val_accuracy improved from -inf to 0.77500, saving model to /content/new_submission/fold5_best_ft.keras\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 1s/step - accuracy: 0.6841 - loss: 0.9479 - val_accuracy: 0.7750 - val_loss: 0.9735 - learning_rate: 5.0000e-06\n",
            "Epoch 2/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.7022 - loss: 0.9980\n",
            "Epoch 2: val_accuracy did not improve from 0.77500\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.7026 - loss: 0.9970 - val_accuracy: 0.7250 - val_loss: 0.9774 - learning_rate: 5.0000e-06\n",
            "Epoch 3/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7077 - loss: 0.9689\n",
            "Epoch 3: val_accuracy did not improve from 0.77500\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.7063 - loss: 0.9696 - val_accuracy: 0.7500 - val_loss: 0.9778 - learning_rate: 5.0000e-06\n",
            "Epoch 4/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6687 - loss: 0.9745\n",
            "Epoch 4: val_accuracy did not improve from 0.77500\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.6678 - loss: 0.9744 - val_accuracy: 0.7500 - val_loss: 0.9778 - learning_rate: 5.0000e-06\n",
            "Epoch 5/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6198 - loss: 1.0508\n",
            "Epoch 5: val_accuracy did not improve from 0.77500\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.6222 - loss: 1.0486 - val_accuracy: 0.7500 - val_loss: 0.9768 - learning_rate: 1.5000e-06\n",
            "Epoch 6/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.7407 - loss: 0.9518\n",
            "Epoch 6: val_accuracy did not improve from 0.77500\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.7390 - loss: 0.9530 - val_accuracy: 0.7500 - val_loss: 0.9759 - learning_rate: 1.5000e-06\n",
            "Epoch 7/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7036 - loss: 0.9424\n",
            "Epoch 7: val_accuracy did not improve from 0.77500\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.7024 - loss: 0.9432 - val_accuracy: 0.7500 - val_loss: 0.9740 - learning_rate: 1.5000e-06\n",
            "Epoch 8/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.6700 - loss: 0.9930\n",
            "Epoch 8: val_accuracy did not improve from 0.77500\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - accuracy: 0.6702 - loss: 0.9927 - val_accuracy: 0.7500 - val_loss: 0.9712 - learning_rate: 4.5000e-07\n",
            "Epoch 9/150\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6768 - loss: 0.9682\n",
            "Epoch 9: val_accuracy did not improve from 0.77500\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.6775 - loss: 0.9680 - val_accuracy: 0.7500 - val_loss: 0.9684 - learning_rate: 4.5000e-07\n",
            "Fold 5 최종 검증 정확도: 0.77500\n",
            "K-Fold 평균 검증 정확도 (5 Folds): 0.72293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7e94720e82c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7e94720e82c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "제출 파일 생성 완료: submission_final_optimized.csv\n"
          ]
        }
      ],
      "execution_count": 1
    }
  ]
}
