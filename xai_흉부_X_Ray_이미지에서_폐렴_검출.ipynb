{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 13939211,
          "sourceType": "datasetVersion",
          "datasetId": 8883475
        }
      ],
      "dockerImageVersionId": 31193,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekdls02/ekdls2025/blob/main/xai_%EA%B3%BC%EC%A0%9C4_%ED%9D%89%EB%B6%80_X_Ray_%EC%9D%B4%EB%AF%B8%EC%A7%80%EC%97%90%EC%84%9C_%ED%8F%90%EB%A0%B4_%EA%B2%80%EC%B6%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.utils import class_weight # 클래스 가중치 계산을 위해 추가\n",
        "import os\n",
        "\n",
        "\n",
        "# 1. 데이터 로드 및 전처리\n",
        "train_npz = np.load(\"/content/train.npz\")\n",
        "test_npz = np.load(\"/content/test.npz\")\n",
        "\n",
        "x_train_raw, y_train_raw = train_npz['x'], train_npz['y']\n",
        "x_test_raw = test_npz['x']\n",
        "\n",
        "def prep_images(x, target=(224,224)):\n",
        "    x_out = []\n",
        "    for im in x:\n",
        "        if im.ndim == 2:  # grayscale\n",
        "            im = im[..., np.newaxis]\n",
        "        r = tf.image.resize(im, target).numpy()\n",
        "        r = np.repeat(r, 3, axis=-1)\n",
        "        x_out.append(r.astype('float32'))\n",
        "    return np.array(x_out)\n",
        "\n",
        "X = prep_images(x_train_raw)\n",
        "X_test = prep_images(x_test_raw)\n",
        "\n",
        "Y_str = y_train_raw.flatten()\n",
        "Y = np.array([1 if v.lower()=='pneumonia' else 0 for v in Y_str])\n",
        "\n",
        "X_train, X_val, Y_train, Y_val, Y_str_train, Y_str_val = train_test_split(\n",
        "    X, Y, Y_str, test_size=0.2, stratify=Y, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# 클래스 가중치 계산\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(Y_train),\n",
        "    y=Y_train\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "print(f\"클래스 가중치 계산 완료: {class_weights}\")\n",
        "\n",
        "\n",
        "# 2.데이터 증강 및 정규화\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_gen_raw = ImageDataGenerator(\n",
        "    rotation_range=15, width_shift_range=0.15, height_shift_range=0.15,\n",
        "    zoom_range=0.15, horizontal_flip=True,\n",
        "    featurewise_center=True, featurewise_std_normalization=True\n",
        ")\n",
        "\n",
        "val_gen_raw = ImageDataGenerator(\n",
        "    featurewise_center=True, featurewise_std_normalization=True\n",
        ")\n",
        "\n",
        "train_gen_raw.fit(X_train)\n",
        "val_gen_raw.fit(X_train)\n",
        "\n",
        "train_gen = train_gen_raw.flow(X_train, Y_train, batch_size=BATCH_SIZE)\n",
        "val_gen = val_gen_raw.flow(X_val, Y_val, batch_size=BATCH_SIZE)\n",
        "\n",
        "\n",
        "# 3. 모델 구축 및 Stage 1 학습 (정규화 미세 조정 적용)\n",
        "checkpoint_path = \"best_model_stage1.weights.h5\"\n",
        "\n",
        "base = ResNet50(weights='imagenet', include_top=False, input_shape=X_train.shape[1:])\n",
        "base.trainable = False\n",
        "\n",
        "x = GlobalAveragePooling2D()(base.output)\n",
        "x = Dropout(0.5)(x) # Dropout 비율 감소 (0.6 -> 0.5)\n",
        "x = Dense(256, activation='relu', kernel_regularizer=l2(1e-5))(x) # L2 강도 감소 (1e-4 -> 1e-5)\n",
        "out = Dense(1, activation='sigmoid')(x)\n",
        "model = Model(base.input, out)\n",
        "\n",
        "model.compile(optimizer=Adam(3e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Stage 1: 분류기 학습\n",
        "es_stage1 = EarlyStopping(monitor='val_accuracy', patience=8, restore_best_weights=True)\n",
        "mc_stage1 = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True, save_weights_only=True, mode='max')\n",
        "\n",
        "print(\"--- Stage 1: 분류기 레이어 학습 (base model frozen) ---\")\n",
        "model.fit(\n",
        "    train_gen,\n",
        "    epochs=20,\n",
        "    validation_data=val_gen,\n",
        "    steps_per_epoch=len(X_train)//BATCH_SIZE,\n",
        "    callbacks=[es_stage1, mc_stage1],\n",
        "    class_weight=class_weights # 클래스 가중치 적용\n",
        ")\n",
        "\n",
        "model.load_weights(checkpoint_path)\n",
        "\n",
        "\n",
        "# 4. Stage 2: Fine-tuning (LR 스케줄러 적용)\n",
        "base.trainable = True\n",
        "\n",
        "print(\"--- Stage 2: Fine-tuning 범위 제한 ---\")\n",
        "trainable_layer_count = 0\n",
        "for layer in base.layers:\n",
        "    if 'conv5_block' in layer.name or 'res5' in layer.name:\n",
        "        layer.trainable = True\n",
        "        trainable_layer_count += 1\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "print(f\"총 학습 가능 레이어 수 (base model 내): {trainable_layer_count}\")\n",
        "\n",
        "# Fine-tuning을 위한 낮은 학습률 (3e-6 유지)\n",
        "model.compile(optimizer=Adam(3e-6), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fine-tuning: 긴 patience\n",
        "es_stage2 = EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)\n",
        "mc_stage2 = ModelCheckpoint(\"best_model_stage2.weights.h5\", monitor='val_accuracy', save_best_only=True, save_weights_only=True, mode='max')\n",
        "# 학습률 스케줄러 추가\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, min_lr=1e-7, verbose=1)\n",
        "\n",
        "\n",
        "print(\"\\n--- Stage 2: Fine-tuning (LR 스케줄러 적용) ---\")\n",
        "model.fit(\n",
        "    train_gen,\n",
        "    epochs=60,\n",
        "    validation_data=val_gen,\n",
        "    steps_per_epoch=len(X_train)//BATCH_SIZE,\n",
        "    callbacks=[es_stage2, mc_stage2, reduce_lr], # LR 스케줄러 추가\n",
        "    class_weight=class_weights # 클래스 가중치 적용\n",
        ")\n",
        "\n",
        "model.load_weights(\"best_model_stage2.weights.h5\")\n",
        "\n",
        "\n",
        "# 5. Threshold 기반 예측\n",
        "X_test_norm = val_gen_raw.standardize(X_test.copy())\n",
        "\n",
        "y_pred_test_proba = model.predict(X_test_norm).flatten()\n",
        "y_pred_class = (y_pred_test_proba > 0.5).astype(int)\n",
        "\n",
        "y_pred_str = np.array(['pneumonia' if x==1 else 'normal' for x in y_pred_class])\n",
        "\n",
        "\n",
        "# 6. 제출 파일 생성\n",
        "submission_path = \"/content/submission.csv\"\n",
        "df_submission = pd.read_csv(submission_path)\n",
        "df_submission['result'] = y_pred_str\n",
        "output_file = \"new_submission.csv\"\n",
        "df_submission.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"제출 파일 생성 완료: {output_file}\")\n",
        "print(\"Positive 개수:\", int((df_submission['result']=='pneumonia').sum()))"
      ],
      "metadata": {
        "id": "lrbOGYFKUh-k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17001fcc-9c44-4238-9072-25d5642b3d04"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "클래스 가중치 계산 완료: {0: np.float64(1.0), 1: np.float64(1.0)}\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "--- Stage 1: 분류기 레이어 학습 (base model frozen) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6s/step - accuracy: 0.5032 - loss: 0.8151 - val_accuracy: 0.6667 - val_loss: 0.6122\n",
            "Epoch 2/20\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.5625 - loss: 0.7778"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 411ms/step - accuracy: 0.5625 - loss: 0.7778 - val_accuracy: 0.7000 - val_loss: 0.5644\n",
            "Epoch 3/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 814ms/step - accuracy: 0.5764 - loss: 0.7434 - val_accuracy: 0.9667 - val_loss: 0.4286\n",
            "Epoch 4/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5625 - loss: 0.6305 - val_accuracy: 0.9667 - val_loss: 0.4047\n",
            "Epoch 5/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 366ms/step - accuracy: 0.6708 - loss: 0.5386 - val_accuracy: 0.9667 - val_loss: 0.3470\n",
            "Epoch 6/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.7500 - loss: 0.4627 - val_accuracy: 0.9667 - val_loss: 0.3244\n",
            "Epoch 7/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 430ms/step - accuracy: 0.8341 - loss: 0.4717 - val_accuracy: 0.9667 - val_loss: 0.2683\n",
            "Epoch 8/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.7812 - loss: 0.4612 - val_accuracy: 0.9667 - val_loss: 0.2525\n",
            "Epoch 9/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 423ms/step - accuracy: 0.8282 - loss: 0.4082 - val_accuracy: 0.9667 - val_loss: 0.2195\n",
            "Epoch 10/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.7812 - loss: 0.5503 - val_accuracy: 0.9667 - val_loss: 0.2116\n",
            "Epoch 11/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 745ms/step - accuracy: 0.8559 - loss: 0.4248 - val_accuracy: 0.9667 - val_loss: 0.1998\n",
            "--- Stage 2: Fine-tuning 범위 제한 ---\n",
            "총 학습 가능 레이어 수 (base model 내): 32\n",
            "\n",
            "--- Stage 2: Fine-tuning (LR 스케줄러 적용) ---\n",
            "Epoch 1/60\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 7s/step - accuracy: 0.6589 - loss: 0.6080 - val_accuracy: 0.9667 - val_loss: 0.4248 - learning_rate: 3.0000e-06\n",
            "Epoch 2/60\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.8125 - loss: 0.5128 - val_accuracy: 0.9667 - val_loss: 0.4239 - learning_rate: 3.0000e-06\n",
            "Epoch 3/60\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 531ms/step - accuracy: 0.7911 - loss: 0.4700 - val_accuracy: 0.9667 - val_loss: 0.4214 - learning_rate: 3.0000e-06\n",
            "Epoch 4/60\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7812 - loss: 0.4798 - val_accuracy: 0.9667 - val_loss: 0.4204 - learning_rate: 3.0000e-06\n",
            "Epoch 5/60\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 384ms/step - accuracy: 0.7408 - loss: 0.5203 - val_accuracy: 0.9667 - val_loss: 0.4172 - learning_rate: 3.0000e-06\n",
            "Epoch 6/60\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.9062 - loss: 0.4611\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 1.500000053056283e-06.\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.9062 - loss: 0.4611 - val_accuracy: 0.9667 - val_loss: 0.4167 - learning_rate: 3.0000e-06\n",
            "Epoch 7/60\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 389ms/step - accuracy: 0.8446 - loss: 0.4175 - val_accuracy: 0.9667 - val_loss: 0.4154 - learning_rate: 1.5000e-06\n",
            "Epoch 8/60\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.8125 - loss: 0.4541 - val_accuracy: 0.9667 - val_loss: 0.4147 - learning_rate: 1.5000e-06\n",
            "Epoch 9/60\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 395ms/step - accuracy: 0.8736 - loss: 0.4380 - val_accuracy: 0.9667 - val_loss: 0.4135 - learning_rate: 1.5000e-06\n",
            "Epoch 10/60\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7812 - loss: 0.4789 - val_accuracy: 0.9667 - val_loss: 0.4129 - learning_rate: 1.5000e-06\n",
            "Epoch 11/60\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.7836 - loss: 0.5046\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 7.500000265281415e-07.\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 465ms/step - accuracy: 0.7809 - loss: 0.5069 - val_accuracy: 0.9667 - val_loss: 0.4119 - learning_rate: 1.5000e-06\n",
            "Epoch 12/60\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.8125 - loss: 0.4161 - val_accuracy: 0.9667 - val_loss: 0.4117 - learning_rate: 7.5000e-07\n",
            "Epoch 13/60\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 469ms/step - accuracy: 0.8424 - loss: 0.4047 - val_accuracy: 0.9667 - val_loss: 0.4110 - learning_rate: 7.5000e-07\n",
            "Epoch 14/60\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.8438 - loss: 0.4089 - val_accuracy: 0.9667 - val_loss: 0.4108 - learning_rate: 7.5000e-07\n",
            "Epoch 15/60\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 634ms/step - accuracy: 0.8242 - loss: 0.4619 - val_accuracy: 0.9667 - val_loss: 0.4106 - learning_rate: 7.5000e-07\n",
            "Epoch 16/60\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.8438 - loss: 0.4056\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 3.7500001326407073e-07.\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.8438 - loss: 0.4056 - val_accuracy: 0.9667 - val_loss: 0.4107 - learning_rate: 7.5000e-07\n",
            "Epoch 17/60\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 396ms/step - accuracy: 0.8768 - loss: 0.4493 - val_accuracy: 0.9667 - val_loss: 0.4108 - learning_rate: 3.7500e-07\n",
            "Epoch 18/60\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.8125 - loss: 0.4465 - val_accuracy: 0.9667 - val_loss: 0.4109 - learning_rate: 3.7500e-07\n",
            "Epoch 19/60\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 386ms/step - accuracy: 0.7905 - loss: 0.4739 - val_accuracy: 0.9667 - val_loss: 0.4112 - learning_rate: 3.7500e-07\n",
            "Epoch 20/60\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9062 - loss: 0.3198 - val_accuracy: 0.9667 - val_loss: 0.4114 - learning_rate: 3.7500e-07\n",
            "Epoch 21/60\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.8741 - loss: 0.3874\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 1.8750000663203537e-07.\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 393ms/step - accuracy: 0.8658 - loss: 0.3973 - val_accuracy: 0.9667 - val_loss: 0.4115 - learning_rate: 3.7500e-07\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5s/step\n",
            "제출 파일 생성 완료: new_submission.csv\n",
            "Positive 개수: 23\n"
          ]
        }
      ]
    }
  ]
}
